{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import chardet\n",
    "\n",
    "# Load the keywords\n",
    "keywords_df = pd.read_csv('keywords.csv', encoding='latin1')\n",
    "keywords = keywords_df['Keyword'].tolist()\n",
    "#lowercase keywords\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "# Get a list of all text files in the TXT directory\n",
    "txt_files = [f for f in os.listdir('TXT') if f.endswith('.txt')]\n",
    "\n",
    "# Prepare the data for the output dataframe\n",
    "data = {\n",
    "    'Filename': [],\n",
    "    'KeywordPresent': [],\n",
    "    'FoundKeywords': []\n",
    "}\n",
    "\n",
    "# Go through all txt files\n",
    "for txt_file in txt_files:\n",
    "    with open(os.path.join('TXT_no_names', txt_file), 'rb') as file:\n",
    "        # Detect file encoding\n",
    "        result = chardet.detect(file.read())\n",
    "    \n",
    "    # Re-open the file with the correct encoding\n",
    "    try:\n",
    "        with open(os.path.join('TXT_no_names', txt_file), 'r', encoding=result['encoding']) as file:\n",
    "            # Read file content\n",
    "            content = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(os.path.join('TXT_no_names', txt_file), 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(os.path.join('TXT_no_names', txt_file), 'r', encoding='latin1') as file:\n",
    "                content = file.read()\n",
    "\n",
    "    # Apply cleaning operations\n",
    "    content = re.sub(r'(\\d+)$', r'\\1.', content, flags=re.MULTILINE)\n",
    "    content = re.sub(r'http\\S+|www\\S+|https\\S+', '', content, flags=re.MULTILINE)\n",
    "    content = re.sub(r'\\.{2,}', '.', content)\n",
    "    content = re.sub(r'\\n\\s*\\n', '\\n', content).strip()\n",
    "    content = re.sub(r'\\n(?=[a-z])', ' ', content)\n",
    "    content = content.lower()\n",
    "\n",
    "    # Find keywords in content\n",
    "    found_keywords = [keyword for keyword in keywords if re.search(r\"\\b%s\\b\" % keyword.replace(\".\", r\"\\.\").replace(\"*\", \"\\w*\"), content)]\n",
    "    \n",
    "    # Append results\n",
    "    data['Filename'].append(txt_file)\n",
    "    data['KeywordPresent'].append(bool(found_keywords))  # Convert to bool\n",
    "    data['FoundKeywords'].append(', '.join(found_keywords))\n",
    "\n",
    "# Create output dataframe and save as CSV\n",
    "output_df = pd.DataFrame(data)\n",
    "output_df.to_csv('output.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
